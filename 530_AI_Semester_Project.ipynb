{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Hsk_Y8df_q",
        "outputId": "832336b1-840d-443e-9648-7b16e686792b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\python39\\lib\\site-packages (4.24.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\eaden\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\python39\\lib\\site-packages (from transformers) (1.23.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\python39\\lib\\site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\python39\\lib\\site-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: filelock in c:\\python39\\lib\\site-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\python39\\lib\\site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in c:\\python39\\lib\\site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\python39\\lib\\site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\python39\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\eaden\\appdata\\roaming\\python\\python39\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: colorama in c:\\users\\eaden\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python39\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python39\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python39\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python39\\lib\\site-packages (from requests->transformers) (1.26.12)\n"
          ]
        }
      ],
      "source": [
        "#Import transformers library from hugging face\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OYzXZGhGd7IL"
      },
      "outputs": [],
      "source": [
        "#Import needed \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertForQuestionAnswering\n",
        "from transformers import BertTokenizer\n",
        "from flask import Flask, render_template, redirect, url_for,request\n",
        "from flask import make_response\n",
        "app = Flask(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "5JQQndAiyceD",
        "outputId": "3c6faf99-b115-4f31-acbf-6ba4105afa04"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>version</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   version                                               data\n",
              "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
              "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
              "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
              "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
              "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#This mounts your Google Drive to the Colab VM\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#Load the SQUAD dataset into the project\n",
        "coqa = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')\n",
        "coqa.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8alXzQjYeTmn"
      },
      "outputs": [],
      "source": [
        "###Clean the data by removing the version column from the dataset and creating a new dataframe\n",
        "###dataframe will be created by attaching every question answer-pair to its corresponding paragraph\n",
        "\n",
        "#Remove the version column from the dataset\n",
        "del coqa['version']\n",
        "\n",
        "#required columns in our dataframe\n",
        "cols = [\"text\",\"question\",\"answer\"]\n",
        "\n",
        "#list of lists to create our dataframe\n",
        "comp_list = []\n",
        "for index, row in coqa.iterrows():\n",
        "    for i in range(len(row[\"data\"][\"questions\"])):\n",
        "        temp_list = []\n",
        "        temp_list.append(row[\"data\"][\"story\"])\n",
        "        temp_list.append(row[\"data\"][\"questions\"][i][\"input_text\"])\n",
        "        temp_list.append(row[\"data\"][\"answers\"][i][\"input_text\"])\n",
        "        comp_list.append(temp_list)\n",
        "\n",
        "new_df = pd.DataFrame(comp_list, columns=cols) \n",
        "#saving the dataframe to csv file for further loading\n",
        "new_df.to_csv(\"CoQA_data.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "EopnHjwvi0Ae",
        "outputId": "c9954f07-e1ec-4691-b8a0-8d74a33ef2a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>When was the Vat formally opened?</td>\n",
              "      <td>It was formally established in 1475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what is the library for?</td>\n",
              "      <td>research</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>for what subjects?</td>\n",
              "      <td>history, and law</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>and?</td>\n",
              "      <td>philosophy, science and theology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what was started in 2014?</td>\n",
              "      <td>a  project</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  The Vatican Apostolic Library (), more commonl...   \n",
              "1  The Vatican Apostolic Library (), more commonl...   \n",
              "2  The Vatican Apostolic Library (), more commonl...   \n",
              "3  The Vatican Apostolic Library (), more commonl...   \n",
              "4  The Vatican Apostolic Library (), more commonl...   \n",
              "\n",
              "                            question                               answer  \n",
              "0  When was the Vat formally opened?  It was formally established in 1475  \n",
              "1           what is the library for?                             research  \n",
              "2                 for what subjects?                     history, and law  \n",
              "3                               and?     philosophy, science and theology  \n",
              "4          what was started in 2014?                           a  project  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_data = pd.read_csv(\"CoQA_data.csv\")\n",
        "clean_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OAmGLbw0xUX",
        "outputId": "3bfacf1c-1101-4e4b-a41c-142a39241cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of question and answers:  108647\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of question and answers: \", len(clean_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lsmlm1M21dnw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 443/443 [00:00<00:00, 221kB/s]\n",
            "c:\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\eaden\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Downloading: 100%|██████████| 1.34G/1.34G [02:02<00:00, 10.9MB/s]\n",
            "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 2.01MB/s]\n",
            "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 13.8kB/s]\n"
          ]
        }
      ],
      "source": [
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad', return_dict=False)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad',return_dict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVJ15eRg2RYk",
        "outputId": "ce158798-78b8-4a1f-85c5-b07acf5c30c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input has a total of 339 tokens.\n",
            "[CLS]        101\n",
            "does       2,515\n",
            "woods      5,249\n",
            "have       2,031\n",
            "a          1,037\n",
            "website    4,037\n",
            "?          1,029\n",
            "[SEP]        102\n",
            "(          1,006\n",
            "cnn       13,229\n",
            ")          1,007\n",
            "-          1,011\n",
            "-          1,011\n",
            "gill      12,267\n",
            "##ette     7,585\n",
            "said       2,056\n",
            "saturday   5,095\n",
            "it         2,009\n",
            "was        2,001\n",
            "\"          1,000\n",
            "limiting  14,879\n",
            "\"          1,000\n",
            "golfer    20,601\n",
            "tiger      6,816\n",
            "woods      5,249\n",
            "'          1,005\n",
            "role       2,535\n",
            "in         1,999\n",
            "its        2,049\n",
            "marketing   5,821\n",
            "programs   3,454\n",
            "to         2,000\n",
            "give       2,507\n",
            "him        2,032\n",
            "the        1,996\n",
            "privacy    9,394\n",
            "he         2,002\n",
            "needs      3,791\n",
            "to         2,000\n",
            "work       2,147\n",
            "on         2,006\n",
            "family     2,155\n",
            "relationships   6,550\n",
            "after      2,044\n",
            "disclosure  19,380\n",
            "##s        2,015\n",
            "of         1,997\n",
            "his        2,010\n",
            "\"          1,000\n",
            "in         1,999\n",
            "##fide    20,740\n",
            "##lity    18,605\n",
            ".          1,012\n",
            "\"          1,000\n",
            "in         1,999\n",
            "a          1,037\n",
            "statement   4,861\n",
            ",          1,010\n",
            "the        1,996\n",
            "boston     3,731\n",
            ",          1,010\n",
            "massachusetts   4,404\n",
            "-          1,011\n",
            "based      2,241\n",
            "body       2,303\n",
            "groom     18,087\n",
            "##ing      2,075\n",
            "company    2,194\n",
            "said       2,056\n",
            "it         2,009\n",
            "supports   6,753\n",
            "woods      5,249\n",
            "'          1,005\n",
            "decision   3,247\n",
            "to         2,000\n",
            "take       2,202\n",
            "\"          1,000\n",
            "an         2,019\n",
            "indefinite  25,617\n",
            "break      3,338\n",
            "\"          1,000\n",
            "from       2,013\n",
            "professional   2,658\n",
            "golf       5,439\n",
            ".          1,012\n",
            "on         2,006\n",
            "his        2,010\n",
            "web        4,773\n",
            "site       2,609\n",
            "friday     5,958\n",
            ",          1,010\n",
            "woods      5,249\n",
            "admitted   4,914\n",
            "to         2,000\n",
            "in         1,999\n",
            "##fide    20,740\n",
            "##lity    18,605\n",
            "and        1,998\n",
            "said       2,056\n",
            "he         2,002\n",
            "was        2,001\n",
            "taking     2,635\n",
            "a          1,037\n",
            "break      3,338\n",
            "from       2,013\n",
            "the        1,996\n",
            "sport      4,368\n",
            "to         2,000\n",
            "focus      3,579\n",
            "on         2,006\n",
            "his        2,010\n",
            "family     2,155\n",
            ".          1,012\n",
            "\"          1,000\n",
            "in         1,999\n",
            "the        1,996\n",
            "midst     12,930\n",
            "of         1,997\n",
            "a          1,037\n",
            "difficult   3,697\n",
            "and        1,998\n",
            "unfortunate  15,140\n",
            "situation   3,663\n",
            ",          1,010\n",
            "we         2,057\n",
            "respect    4,847\n",
            "the        1,996\n",
            "action     2,895\n",
            "tiger      6,816\n",
            "is         2,003\n",
            "taking     2,635\n",
            "to         2,000\n",
            "restore    9,239\n",
            "the        1,996\n",
            "trust      3,404\n",
            "of         1,997\n",
            "his        2,010\n",
            "family     2,155\n",
            ",          1,010\n",
            "friends    2,814\n",
            "and        1,998\n",
            "fans       4,599\n",
            ",          1,010\n",
            "\"          1,000\n",
            "gill      12,267\n",
            "##ette     7,585\n",
            "spokesman  14,056\n",
            "mike       3,505\n",
            "norton    10,770\n",
            "said       2,056\n",
            "in         1,999\n",
            "the        1,996\n",
            "statement   4,861\n",
            ".          1,012\n",
            "\"          1,000\n",
            "we         2,057\n",
            "fully      3,929\n",
            "support    2,490\n",
            "him        2,032\n",
            "stepping   9,085\n",
            "back       2,067\n",
            "from       2,013\n",
            "his        2,010\n",
            "professional   2,658\n",
            "career     2,476\n",
            "and        1,998\n",
            "taking     2,635\n",
            "the        1,996\n",
            "time       2,051\n",
            "he         2,002\n",
            "needs      3,791\n",
            "to         2,000\n",
            "do         2,079\n",
            "what       2,054\n",
            "matters    5,609\n",
            "most       2,087\n",
            ".          1,012\n",
            "we         2,057\n",
            "wish       4,299\n",
            "him        2,032\n",
            "and        1,998\n",
            "his        2,010\n",
            "family     2,155\n",
            "the        1,996\n",
            "best       2,190\n",
            ".          1,012\n",
            "\"          1,000\n",
            "as         2,004\n",
            "tiger      6,816\n",
            "takes      3,138\n",
            "a          1,037\n",
            "break      3,338\n",
            "from       2,013\n",
            "the        1,996\n",
            "public     2,270\n",
            "eye        3,239\n",
            ",          1,010\n",
            "we         2,057\n",
            "will       2,097\n",
            "support    2,490\n",
            "his        2,010\n",
            "desire     4,792\n",
            "for        2,005\n",
            "privacy    9,394\n",
            "by         2,011\n",
            "limiting  14,879\n",
            "his        2,010\n",
            "role       2,535\n",
            "in         1,999\n",
            "our        2,256\n",
            "marketing   5,821\n",
            "programs   3,454\n",
            ",          1,010\n",
            "\"          1,000\n",
            "norton    10,770\n",
            "said       2,056\n",
            ".          1,012\n",
            "woods      5,249\n",
            "'          1,005\n",
            "friday     5,958\n",
            "posting   14,739\n",
            "said       2,056\n",
            ":          1,024\n",
            "\"          1,000\n",
            "after      2,044\n",
            "much       2,172\n",
            "soul       3,969\n",
            "searching   6,575\n",
            ",          1,010\n",
            "i          1,045\n",
            "have       2,031\n",
            "decided    2,787\n",
            "to         2,000\n",
            "take       2,202\n",
            "an         2,019\n",
            "indefinite  25,617\n",
            "break      3,338\n",
            "from       2,013\n",
            "professional   2,658\n",
            "golf       5,439\n",
            ".          1,012\n",
            "i          1,045\n",
            "need       2,342\n",
            "to         2,000\n",
            "focus      3,579\n",
            "my         2,026\n",
            "attention   3,086\n",
            "on         2,006\n",
            "being      2,108\n",
            "a          1,037\n",
            "better     2,488\n",
            "husband    3,129\n",
            ",          1,010\n",
            "father     2,269\n",
            "and        1,998\n",
            "person     2,711\n",
            ".          1,012\n",
            "\"          1,000\n",
            "\"          1,000\n",
            "i          1,045\n",
            "am         2,572\n",
            "deeply     6,171\n",
            "aware      5,204\n",
            "of         1,997\n",
            "the        1,996\n",
            "disappointment  10,520\n",
            "and        1,998\n",
            "hurt       3,480\n",
            "that       2,008\n",
            "my         2,026\n",
            "in         1,999\n",
            "##fide    20,740\n",
            "##lity    18,605\n",
            "has        2,038\n",
            "caused     3,303\n",
            "to         2,000\n",
            "so         2,061\n",
            "many       2,116\n",
            "people     2,111\n",
            ",          1,010\n",
            "most       2,087\n",
            "of         1,997\n",
            "all        2,035\n",
            "my         2,026\n",
            "wife       2,564\n",
            "and        1,998\n",
            "children   2,336\n",
            ",          1,010\n",
            "\"          1,000\n",
            "woods      5,249\n",
            "'          1,005\n",
            "statement   4,861\n",
            "said       2,056\n",
            ".          1,012\n",
            "\"          1,000\n",
            "i          1,045\n",
            "want       2,215\n",
            "to         2,000\n",
            "say        2,360\n",
            "again      2,153\n",
            "to         2,000\n",
            "everyone   3,071\n",
            "that       2,008\n",
            "i          1,045\n",
            "am         2,572\n",
            "profoundly  28,089\n",
            "sorry      3,374\n",
            "and        1,998\n",
            "that       2,008\n",
            "i          1,045\n",
            "ask        3,198\n",
            "forgiveness  17,213\n",
            ".          1,012\n",
            "it         2,009\n",
            "may        2,089\n",
            "not        2,025\n",
            "be         2,022\n",
            "possible   2,825\n",
            "to         2,000\n",
            "repair     7,192\n",
            "the        1,996\n",
            "damage     4,053\n",
            "i          1,045\n",
            "'          1,005\n",
            "ve         2,310\n",
            "done       2,589\n",
            ",          1,010\n",
            "but        2,021\n",
            "i          1,045\n",
            "want       2,215\n",
            "to         2,000\n",
            "do         2,079\n",
            "my         2,026\n",
            "best       2,190\n",
            "to         2,000\n",
            "try        3,046\n",
            ".          1,012\n",
            "\"          1,000\n",
            "[SEP]        102\n"
          ]
        }
      ],
      "source": [
        "#Example Question ans Answer pair in imported model\n",
        "random_num = np.random.randint(0,len(clean_data))\n",
        "question = clean_data[\"question\"][random_num]\n",
        "text = clean_data[\"text\"][random_num]\n",
        "input_ids = tokenizer.encode(question, text)\n",
        "print(\"The input has a total of {} tokens.\".format(len(input_ids)))\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "for token, id in zip(tokens, input_ids):\n",
        "    print('{:8}{:8,}'.format(token,id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oUwpLs2Wu8l2"
      },
      "outputs": [],
      "source": [
        "# Search the input_ids for the first instance of the `[SEP]` token.\n",
        "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "# The number of segment A tokens includes the [SEP] token istelf.\n",
        "num_seg_a = sep_index + 1\n",
        "\n",
        "# The remainder are segment B.\n",
        "num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "# Construct the list of 0s and 1s.\n",
        "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "# There should be a segment_id for every input token.\n",
        "assert len(segment_ids) == len(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JJe7XgNFwGq2"
      },
      "outputs": [],
      "source": [
        "# Run our example through the model.\n",
        "start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
        "                                 token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84HCzdD2xpin",
        "outputId": "4e614d7c-a3de-4b7a-c22e-8b21aae2ba33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Does Woods have a website?\n",
            "Answer: \"his web site friday\"\n"
          ]
        }
      ],
      "source": [
        "# Find the tokens with the highest `start` and `end` scores.\n",
        "answer_start = torch.argmax(start_scores)\n",
        "answer_end = torch.argmax(end_scores)\n",
        "\n",
        "# Combine the tokens in the answer and print it out.\n",
        "# First start with the first token.\n",
        "answer = tokens[answer_start]\n",
        "\n",
        "# Select the remaining answer tokens and join them with whitespace.\n",
        "for i in range(answer_start + 1, answer_end + 1):\n",
        "    \n",
        "\n",
        "    #Reverses wordpiece tokenization ==> If it's a subword token, then recombine it with the previous token.\n",
        "    #Wordpiece tokenization ==> rare words get broken down into subword/pieces\n",
        "    #                       ==> '##' used to delimit tokens that have been split\n",
        "    if tokens[i][0:2] == '##':\n",
        "        answer += tokens[i][2:]\n",
        "    \n",
        "    # Otherwise, add a space then the token.\n",
        "    else:\n",
        "        answer += ' ' + tokens[i]\n",
        "\n",
        "print('Question: ' + question)\n",
        "print('Answer: \"' + answer + '\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8WSpHoE_0jvf"
      },
      "outputs": [],
      "source": [
        "@app.route('/processQuestion')\n",
        "def question_answer():\n",
        "    #quest, inputtext;\n",
        "    #tokenize question and text as a pair\n",
        "    input_ids = tokenizer.encode(question, text)\n",
        "    \n",
        "    #string version of tokenized ids\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    \n",
        "    #segment IDs\n",
        "    #first occurence of [SEP] token\n",
        "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
        "    #number of tokens in segment A (question)\n",
        "    num_seg_a = sep_idx+1\n",
        "    #number of tokens in segment B (text)\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "    \n",
        "    #list of 0s and 1s for segment embeddings\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "    \n",
        "    #model output using input_ids and segment_ids\n",
        "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
        "    \n",
        "    #reconstructing the answer\n",
        "    answer_start = torch.argmax(output.start_logits)\n",
        "    answer_end = torch.argmax(output.end_logits)\n",
        "    if answer_end >= answer_start:\n",
        "        answer = tokens[answer_start]\n",
        "        for i in range(answer_start+1, answer_end+1):\n",
        "            if tokens[i][0:2] == \"##\":\n",
        "                answer += tokens[i][2:]\n",
        "            else:\n",
        "                answer += \" \" + tokens[i]\n",
        "                \n",
        "    if answer.startswith(\"[CLS]\"):\n",
        "        answer = \"Unable to find the answer to your question.\"\n",
        "    \n",
        "    print(\"\\nPredicted answer:\\n{}\".format(answer.capitalize()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
